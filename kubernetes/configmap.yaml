apiVersion: v1
data:
  config.txt: |
    # Directory where to store the VectorDB
    vectorstore=/vectorstore
    # Ollama model for text rendering
    embeddingmodel=nomic-embed-text
    # Ollama model for deep think
    mainmodel=deepseek-r1:7b
    # Deep of the web crawler
    crawldeep=2
    # Used vector results for deep think, be careful
    vectorresults=4
    # Listen address for web ui
    servername=0.0.0.0
    # Listen port for web ui
    serverport=9000
    # web ui theme: Base, Default, Glass, Monochrome, Soft
    theme=Monochrome
kind: ConfigMap
metadata:
  name: ollama-chatbot
---
apiVersion: v1
data:
  urls.txt: |
    https://k8sblog.eumel.de
    https://github.com/eumel8/cosignwebhook/blob/main/README.md
    https://api.github.com/repos/eumel8/cosignwebhook
    #https://github.com/eumel8/overlaytest/blob/main/README.md
    #http://gitrepo.ollama-chatbot/repo/
kind: ConfigMap
metadata:
  name: urls
---
apiVersion: v1
data:
  run.sh: |
    #!/bin/sh
    ollama pull nomic-embed-text
    ollama pull deepseek-r1:7b
    python3 web_crawler.py --urls ./urls/urls.txt --config ./chatbot-config/config.txt
    touch /vectorstore/crawl_ready
    sleep infinity
kind: ConfigMap
metadata:
  name: run-crawler
---
apiVersion: v1
data:
  run.sh: |
    #!/bin/sh
    while [ ! -e "/vectorstore/crawl_ready" ]; do
    echo "Crawler not ready, waiting..."
    sleep 5
    done
    echo "Crawler finished, started ui"
    python3 web_ui.py --config ./chatbot-config/config.txt
kind: ConfigMap
metadata:
  name: run-ui
