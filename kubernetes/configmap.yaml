apiVersion: v1
data:
  config.txt: |
    # Directory where to store the VectorDB
    vectorstore=/vectorstore
    # Ollama model for text rendering
    embeddingmodel=nomic-embed-text
    # Ollama model for deep think
    mainmodel=deepseek-r1:7b
    # Deep of the web crawler
    crawldeep=5
    # Used vector results for deep think, be careful
    vectorresults=8
    # Listen address for web ui
    servername=0.0.0.0
    # Listen port for web ui
    serverport=9000
    # web ui theme: Base, Default, Glass, Monochrome, Soft
    theme=Monochrome
kind: ConfigMap
metadata:
  name: ollama-chatbot
---
apiVersion: v1
data:
  urls.txt: |
    http://gitrepo.ollama-chatbot/repo/
    #https://github.com/eumel8/cosignwebhook/blob/main/README.md
    #https://api.github.com/repos/eumel8/cosignwebhook
    #https://github.com/eumel8/overlaytest/blob/main/README.md
kind: ConfigMap
metadata:
  name: urls
---
apiVersion: v1
data:
  run.sh: |
    #!/bin/sh
    #ollama pull nomic-embed-text
    #ollama pull deepseek-r1:7b
    python3 web_crawler.py --urls ./urls/urls.txt --config ./chatbot-config/config.txt
    touch /vectorstore/crawl_ready
    sleep infinity
kind: ConfigMap
metadata:
  name: run-crawler
---
apiVersion: v1
data:
  run.sh: |
    #!/bin/sh
    ollama pull deepseek-r1:7b
    ollama pull nomic-embed-text
    python3 web_ui.py --config ./chatbot-config/config.txt
kind: ConfigMap
metadata:
  name: run-ui
